{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv playwright requests beautifulsoup4 langchain langgraph langchain-google-genai pdfminer.six\n",
        "\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "PSsBZ3UKurOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()w\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import TypedDict, Optional\n"
      ],
      "metadata": {
        "id": "hjWoF3uDuiei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dMXeA2qpitRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df8e1ac-92a0-4210-de6b-ab607420bba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Email: intisatyapriya@gmail.com\n",
            "API Key: AIzaSy*****\n",
            "Scraping LinkedIn profile...\n",
            "\n",
            "--- Extracted LinkedIn Data ---\n",
            "Headline: Experienced Robotics Process Automation developer with a demonstrated history of working in the information technology and services industry. Skilled in UiPath, C#, Core Java, Robotic Process Automation (RPA), and . Strong engineering professional with a Bachelor of Technology - BTech focused in Computer Science from Pondicherry University.\n",
            "Skills: Python (Programming Language), Machine Learning, 1, Data Visualization, .NET Framework, Automation Anywhere, Core Java, Robotic Process Automation (RPA), C (Programming Language), UiPath, C#, Teamwork, Data Analysis, Digital Marketing, 4, Marketing Tools: Digital Marketing Tools and Services, C++\n",
            "Education: 1, 4, Goa Institute of Management (GIM), Postgraduate Degree, Big Data Analytics, Jun 2024 - Jun 2026, Sri Manakula Vinayagar Engineering College, Bachelor of Technology - BTech, Computer Science, 2016 - 2020, St. Patrick M.H.S.S, 2004 - 2016\n",
            "\n",
            "Scraping GitHub profile...\n",
            "\n",
            "\n",
            "====== Final Candidate Evaluation ======\n",
            "\n",
            "**Overall Score: 50/100**\n",
            "\n",
            "**Strengths:**\n",
            "\n",
            "* **Quantifiable Achievements:** The candidate demonstrates a good understanding of the importance of quantifying achievements on their resume, which is a valuable skill for a data analyst.\n",
            "* **Technical Skills:**  The candidate possesses a relevant skillset for a Data Analyst Intern role, including Python, SQL, Tableau, and experience with RPA (though not directly applicable, it demonstrates technical aptitude).\n",
            "* **Project Experience:**  Inclusion of project details, even academic ones, shows initiative and provides talking points for an interview.\n",
            "\n",
            "\n",
            "**Areas for Improvement:**\n",
            "\n",
            "* **Consistency and Professionalism:**  The candidate needs to significantly improve the consistency and professionalism of their resume and LinkedIn profile. This includes addressing formatting inconsistencies, repetitive information, unclear wording, and grammatical errors.\n",
            "* **Focus and Relevance:**  The resume and LinkedIn profile lack focus. The emphasis on RPA, while showcasing technical skills, doesn't align perfectly with the Data Analyst Intern role. The candidate should tailor their materials to highlight data analysis skills and experience more prominently.  Irrelevant skills like Digital Marketing should be removed from the LinkedIn profile.\n",
            "* **Clarity and Conciseness:** The candidate needs to work on conveying information clearly and concisely, especially on LinkedIn. The headline is verbose and generic, and the skills section is unfocused.  The resume's \"Positions of Responsibilities\" and \"Extra-Curricular Activities\" sections need refinement.\n",
            "* **GitHub Profile:**  The completely blank GitHub profile is a major missed opportunity.  The candidate needs to populate their profile with relevant information, projects, and contributions to demonstrate their coding skills and experience.\n",
            "* **LinkedIn Profile Optimization:** The LinkedIn profile needs significant improvement beyond the headline and skills.  A compelling summary/about section, detailed experience section using the STAR method, and recommendations are crucial for a strong profile.\n",
            "* **Resume Structure and Content:** The resume needs structural improvements, including a compelling summary/objective, a clearer academic record section, and better organization of information.\n",
            "\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "While the candidate possesses some of the technical skills required for a Data Analyst Intern role, their application materials lack polish and focus. The inconsistencies in formatting, repetitive information, and lack of a strong online presence (especially the empty GitHub profile) significantly detract from their overall score.  By addressing the specific recommendations provided in the feedback, the candidate can significantly improve their chances of securing an interview. The candidate needs to demonstrate a clearer understanding of the Data Analyst role and tailor their application materials accordingly.\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# STEP 0: Mount Drive & Load Credentials\n",
        "# ---------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "ENV_PATH = \"/content/drive/MyDrive/cred.env\"  \n",
        "load_dotenv(ENV_PATH)\n",
        "\n",
        "LINKEDIN_EMAIL = os.getenv(\"LINKEDIN_EMAIL\")\n",
        "LINKEDIN_PASSWORD = os.getenv(\"LINKEDIN_PASSWORD\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "print(\"Email:\", LINKEDIN_EMAIL)\n",
        "print(\"API Key:\", GOOGLE_API_KEY[:6] + \"*****\")\n",
        "\n",
        
        "# STEP 1: LinkedIn Scraping using Playwright\n",
        "\n",
        "async def scrape_linkedin(profile_url):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        # Login\n",
        "        await page.goto(\"https://www.linkedin.com/login\")\n",
        "        await page.fill('input#username', LINKEDIN_EMAIL)\n",
        "        await page.fill('input#password', LINKEDIN_PASSWORD)\n",
        "        await page.click('button[type=\"submit\"]')\n",
        "        await page.wait_for_url(\"https://www.linkedin.com/feed/\", timeout=15000)\n",
        "\n",
        "        # Visit profile page\n",
        "        await page.goto(profile_url)\n",
        "        await page.wait_for_timeout(5000)\n",
        "\n",
        "        # Extract headline\n",
        "        try:\n",
        "            headline = await page.locator('div.inline-show-more-text--is-collapsed.full-width').first.inner_text()\n",
        "            headline = headline.split('\\n')[0].strip()\n",
        "        except:\n",
        "            headline = \"Headline not found\"\n",
        "\n",
        "        # Extract skills\n",
        "        skills_url = profile_url + \"/details/skills/\"\n",
        "        await page.goto(skills_url)\n",
        "        await page.wait_for_timeout(5000)\n",
        "\n",
        "        skills = []\n",
        "        try:\n",
        "            skill_elements = await page.locator('span[aria-hidden=\"true\"]').all()\n",
        "            for skill_el in skill_elements:\n",
        "                s = await skill_el.inner_text()\n",
        "                if s.strip():\n",
        "                    skills.append(s.strip())\n",
        "            if \"More profiles for you\" in skills:\n",
        "              index = skills.index(\"More profiles for you\")\n",
        "              skills = skills[:index]\n",
        "        except:\n",
        "            skills = []\n",
        "        skills = list(set(skills))\n",
        "\n",
        "        # Extract education\n",
        "        education_url = profile_url + \"/details/education/\"\n",
        "        await page.goto(education_url)\n",
        "        await page.wait_for_timeout(5000)\n",
        "\n",
        "        education = []\n",
        "        try:\n",
        "            edu_elements = await page.locator('span[aria-hidden=\"true\"]').all()\n",
        "            for edu_el in edu_elements:\n",
        "                e = await edu_el.inner_text()\n",
        "                if e.strip():\n",
        "                    education.append(e.strip())\n",
        "            if \"More profiles for you\" in education:\n",
        "              index = education.index(\"More profiles for you\")\n",
        "              education = education[:index]\n",
        "\n",
        "        except:\n",
        "            education = []\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "        return {\n",
        "            \"headline\": headline,\n",
        "            \"skills\": skills,\n",
        "            \"education\": education\n",
        "        }\n",
        "\n",
        "# Run the async scraper in Colab\n",
        "def run_scraper(url):\n",
        "    return asyncio.run(scrape_linkedin(url))\n",
        "\n",
        "# STEP 2: Extract Resume Text\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_resume_text(resume_path):\n",
        "    return extract_text(resume_path)\n",
        "\n",

        "# STEP 3: Scrape GitHub Profile\n",
        "def scrape_github(github_url):\n",
        "    try:\n",
        "        response = requests.get(github_url)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        text = soup.get_text(separator=\"\\n\")\n",
        "        return text[:3000]  # Limit for LLM prompt\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching GitHub: {e}\"\n",
        "\n",

        "# STEP 4: LangChain & LangGraph Evaluation Setup\n",

        "# Setup Gemini LLM client\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "class EvalState(TypedDict):\n",
        "    resume_path: Optional[str]\n",
        "    resume_text: Optional[str]\n",
        "    linkedin_url: Optional[str]\n",
        "    linkedin_data: Optional[dict]\n",
        "    github_url: Optional[str]\n",
        "    github_text: Optional[str]\n",
        "    job_title: Optional[str]\n",
        "    job_description: Optional[str]\n",
        "    resume_score: Optional[str]\n",
        "    linkedin_score: Optional[str]\n",
        "    github_score: Optional[str]\n",
        "    final_score: Optional[str]\n",
        "\n",
        "@tool\n",
        "def resume_evaluator(resume_text: str) -> str:\n",
        "    \"\"\"Evaluates resume text and returns a score out of 100 with feedback.\"\"\"\n",
        "    prompt = f\"Evaluate the following resume text and provide a score out of 100 with detailed feedback:\\n\\n{resume_text}\"\n",
        "    return llm.invoke(prompt).content\n",
        "\n",
        "@tool\n",
        "def linkedin_evaluator(linkedin_data: dict) -> str:\n",
        "    \"\"\"Evaluates LinkedIn profile data and returns a score out of 100 with detailed feedback.\"\"\"\n",
        "    prompt = (\n",
        "        f\"Evaluate the following LinkedIn profile details(skills,headline and education sections) and provide a score out of 100 with detailed feedback:\\n\\n\"\n",
        "        f\"Headline: {linkedin_data.get('headline', '')}\\n\"\n",
        "        f\"Skills: {', '.join(linkedin_data.get('skills', []))}\\n\"\n",
        "        f\"Education: {', '.join(linkedin_data.get('education', []))}\\n\"\n",
        "    )\n",
        "    return llm.invoke(prompt).content\n",
        "\n",
        "@tool\n",
        "def github_evaluator(github_text: str) -> str:\n",
        "    \"\"\"Evaluates GitHub profile text and returns a score out of 100 with detailed feedback.\"\"\"\n",
        "    prompt = f\"Evaluate the following GitHub profile summary and provide a score out of 100 with detailed feedback:\\n\\n{github_text}\"\n",
        "    return llm.invoke(prompt).content\n",
        "\n",
        "\n",
        "def extract_resume(state: EvalState) -> EvalState:\n",
        "    if state.get(\"resume_path\"):\n",
        "        state[\"resume_text\"] = extract_resume_text(state[\"resume_path\"])\n",
        "    return state\n",
        "\n",
        "def evaluate_resume(state: EvalState) -> EvalState:\n",
        "    state[\"resume_score\"] = resume_evaluator.invoke({\"resume_text\": state[\"resume_text\"]})\n",
        "    return state\n",
        "\n",
        "def evaluate_linkedin(state: EvalState) -> EvalState:\n",
        "    # Use the linkedin_data dictionary collected by scraper\n",
        "    state[\"linkedin_score\"] = linkedin_evaluator.invoke({\"linkedin_data\": state[\"linkedin_data\"]})\n",
        "    return state\n",
        "\n",
        "def evaluate_github(state: EvalState) -> EvalState:\n",
        "    state[\"github_score\"] = github_evaluator.invoke({\"github_text\": state[\"github_text\"]})\n",
        "    return state\n",
        "\n",
        "def compile_feedback(state: EvalState) -> EvalState:\n",
        "    prompt = (\n",
        "        f\"You are evaluating a candidate for the role of **{state['job_title']}**.\\n\"\n",
        "        f\"Job Description:\\n{state['job_description']}\\n\\n\"\n",
        "        f\"Resume Feedback:\\n{state['resume_score']}\\n\\n\"\n",
        "        f\"LinkedIn Feedback:\\n{state['linkedin_score']}\\n\\n\"\n",
        "        f\"GitHub Feedback:\\n{state['github_score']}\\n\\n\"\n",
        "        f\"Based on the above, give an overall score out of 100 and summarize strengths and areas to improve.\"\n",
        "    )\n",
        "    state[\"final_score\"] = llm.invoke(prompt).content\n",
        "    return state\n",
        "\n",
        "\n",
        "builder = StateGraph(EvalState)\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "builder.add_node(\"extract_resume\", RunnableLambda(extract_resume))\n",
        "builder.add_node(\"evaluate_resume\", RunnableLambda(evaluate_resume))\n",
        "builder.add_node(\"evaluate_linkedin\", RunnableLambda(evaluate_linkedin))\n",
        "builder.add_node(\"evaluate_github\", RunnableLambda(evaluate_github))\n",
        "builder.add_node(\"compile_feedback\", RunnableLambda(compile_feedback))\n",
        "\n",
        "builder.set_entry_point(\"extract_resume\")\n",
        "builder.add_edge(\"extract_resume\", \"evaluate_resume\")\n",
        "builder.add_edge(\"evaluate_resume\", \"evaluate_linkedin\")\n",
        "builder.add_edge(\"evaluate_linkedin\", \"evaluate_github\")\n",
        "builder.add_edge(\"evaluate_github\", \"compile_feedback\")\n",
        "builder.set_finish_point(\"compile_feedback\")\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "# STEP 5: Run full evaluation example\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    linkedin_profile_url = \"https://www.linkedin.com/in/inti-harshini\"\n",
        "    resume_pdf_path = \"/content/B2024150_IntiHarshini_CV (6).pdf\"\n",
        "    github_url = \"https://github.com/intiharshini\"\n",
        "\n",
        "    print(\"Scraping LinkedIn profile...\")\n",
        "    linkedin_data = run_scraper(linkedin_profile_url)\n",
        "    print(\"\\n--- Extracted LinkedIn Data ---\")\n",
        "    print(f\"Headline: {linkedin_data.get('headline', 'N/A')}\")\n",
        "    print(f\"Skills: {', '.join(linkedin_data.get('skills', []))}\")\n",
        "    print(f\"Education: {', '.join(linkedin_data.get('education', []))}\\n\")\n",
        "\n",
        "    print(\"Scraping GitHub profile...\")\n",
        "    github_text = scrape_github(github_url)\n",
        "\n",
        "    state = {\n",
        "        \"resume_path\": resume_pdf_path,\n",
        "        \"linkedin_url\": linkedin_profile_url,\n",
        "        \"linkedin_data\": linkedin_data,\n",
        "        \"github_url\": github_url,\n",
        "        \"github_text\": github_text,\n",
        "        \"job_title\": \"Data Analyst Intern\",\n",
        "        \"job_description\": (\n",
        "            \"Looking for a data analyst intern skilled in Python, SQL, Excel, and data visualization tools like Power BI or Tableau. \"\n",
        "            \"Understanding of statistics and ability to communicate findings effectively is essential. \"\n",
        "            \"Must have experience with GitHub and collaborative tools.\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "    result = graph.invoke(state)\n",
        "\n",
        "    print(\"\\n\\n====== Final Candidate Evaluation ======\\n\")\n",
        "    print(result[\"final_score\"])\n"
      ]
    }
  ]
}
